{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Step 0: Local Setup (VS Code)\n",
        "# =============================================================================\n",
        "\n",
        "import sys\n",
        "print(sys.executable)\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "# --- 1. Check GPU ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == 'cpu':\n",
        "    print(\"WARNING: No GPU found. Grad-CAM might be slow!\")\n",
        "\n",
        "# --- 2. Define Local Paths ---\n",
        "# Assuming 'archive.zip' is in the same folder as this notebook\n",
        "BASE_DIR = \".\" \n",
        "DATASET_ZIP_PATH = os.path.join(BASE_DIR, \"archive.zip\")\n",
        "EXTRACT_PATH = os.path.join(BASE_DIR, \"concrete_data\")\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"models\") # Put your .pth files here!\n",
        "\n",
        "POSITIVE_DIR_NAME = \"Positive\"\n",
        "NEGATIVE_DIR_NAME = \"Negative\"\n",
        "\n",
        "# --- 3. Extract Data (Only if needed) ---\n",
        "if not os.path.exists(EXTRACT_PATH):\n",
        "    print(\"Extracting dataset locally...\")\n",
        "    with zipfile.ZipFile(DATASET_ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(EXTRACT_PATH)\n",
        "    print(\"Done.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n",
        "\n",
        "# --- 4. Prepare Validation Loader ---\n",
        "# We only need the validation set for Error Analysis\n",
        "print(\"Preparing DataLoaders...\")\n",
        "\n",
        "positive_path = os.path.join(EXTRACT_PATH, POSITIVE_DIR_NAME)\n",
        "negative_path = os.path.join(EXTRACT_PATH, NEGATIVE_DIR_NAME)\n",
        "\n",
        "positive_files = [(os.path.join(positive_path, f), 1) for f in os.listdir(positive_path) if f.endswith('.jpg')]\n",
        "negative_files = [(os.path.join(negative_path, f), 0) for f in os.listdir(negative_path) if f.endswith('.jpg')]\n",
        "all_files = positive_files + negative_files\n",
        "\n",
        "# Re-create the split logic to get the EXACT same validation set\n",
        "df = pd.DataFrame(all_files, columns=['filepath', 'label'])\n",
        "X = df['filepath']\n",
        "y = df['label']\n",
        "\n",
        "# 70% Train, 30% Temp\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "# 15% Val, 15% Test\n",
        "X_val, _, y_val, _ = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Custom Dataset Class (No need to copy files on disk locally)\n",
        "class ConcreteDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, filepaths, labels, transform=None):\n",
        "        self.filepaths = filepaths.values\n",
        "        self.labels = labels.values\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.filepaths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Transforms\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_dataset = ConcreteDataset(X_val, y_val, transform=val_transforms)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "print(f\"Validation Set Ready: {len(val_dataset)} images.\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Step 1: Define Model Architectures\n",
        "# =============================================================================\n",
        "\n",
        "# --- OPNet Definition ---\n",
        "class OPNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OPNet, self).__init__()\n",
        "        self.block1 = nn.Sequential(nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2, 2))\n",
        "        self.block2 = nn.Sequential(nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2, 2))\n",
        "        self.block3 = nn.Sequential(nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2, 2))\n",
        "        self.block4 = nn.Sequential(nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2, 2))\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(nn.Dropout(p=0.5), nn.Linear(256, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x); x = self.block2(x); x = self.block3(x); x = self.block4(x)\n",
        "        x = self.global_avg_pool(x).view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# --- Loading Function ---\n",
        "def load_model_local(model_name, epoch):\n",
        "    print(f\"Loading {model_name} (Epoch {epoch})...\")\n",
        "    if model_name == \"MobileNetV2\":\n",
        "        model = models.mobilenet_v2(weights=None)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n",
        "    else:\n",
        "        model = OPNet()\n",
        "    \n",
        "    path = os.path.join(MODEL_DIR, f\"{model_name.replace(' ', '_')}_epoch_{epoch}.pth\")\n",
        "    # Load with map_location to ensure it works even if saved on different GPU\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# LOAD YOUR MODELS HERE (Adjust epoch numbers if needed!)\n",
        "best_mobilenet = load_model_local(\"MobileNetV2\", epoch=6)\n",
        "best_opnet = load_model_local(\"OPNet\", epoch=9)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Step 2: Error Analysis (10) & Grad-CAM (11)\n",
        "# =============================================================================\n",
        "\n",
        "# --- Analysis Functions ---\n",
        "def find_errors(model, loader, num=4):\n",
        "    fps, fns = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.unsqueeze(1).float().to(device)\n",
        "            preds = (torch.sigmoid(model(inputs)) > 0.5).float()\n",
        "            \n",
        "            for i in ((preds == 1) & (labels == 0)).nonzero(as_tuple=True)[0]:\n",
        "                if len(fps) < num: fps.append(inputs[i].cpu())\n",
        "            for i in ((preds == 0) & (labels == 1)).nonzero(as_tuple=True)[0]:\n",
        "                if len(fns) < num: fns.append(inputs[i].cpu())\n",
        "            if len(fps) >= num and len(fns) >= num: break\n",
        "    return fps, fns\n",
        "\n",
        "class GradCAM:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model; self.gradients = None; self.activations = None\n",
        "        self.h1 = target_layer.register_forward_hook(self.save_act)\n",
        "        self.h2 = target_layer.register_full_backward_hook(self.save_grad)\n",
        "    def save_act(self, m, i, o): self.activations = o\n",
        "    def save_grad(self, m, i, o): self.gradients = o[0]\n",
        "    def remove(self): self.h1.remove(); self.h2.remove()\n",
        "    def __call__(self, x):\n",
        "        out = self.model(x); self.model.zero_grad(); out[:, 0].backward(retain_graph=True)\n",
        "        w = torch.mean(self.gradients, dim=(2, 3), keepdim=True)\n",
        "        cam = torch.nn.functional.relu(torch.sum(w * self.activations, dim=1, keepdim=True))\n",
        "        cam = torch.nn.functional.interpolate(cam, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "        return cam.detach().cpu().numpy()\n",
        "\n",
        "def plot_analysis(images, cam_obj, model_name, title):\n",
        "    if not images: return\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    norm = transforms.Normalize([-0.485/0.229, -0.456/0.224, -0.406/0.225], [1/0.229, 1/0.224, 1/0.225])\n",
        "    for i, img_tensor in enumerate(images[:4]):\n",
        "        input_t = img_tensor.unsqueeze(0).to(device); input_t.requires_grad = True\n",
        "        mask = cam_obj(input_t)[0, 0]\n",
        "        mask = (mask - mask.min()) / (mask.max() - mask.min() + 1e-7)\n",
        "        img = norm(img_tensor).permute(1, 2, 0).numpy()\n",
        "        plt.subplot(1, 4, i+1); plt.imshow(np.clip(img, 0, 1)); plt.imshow(mask, alpha=0.5, cmap='jet')\n",
        "        plt.title(f\"{model_name} Error {i+1}\"); plt.axis('off')\n",
        "    plt.suptitle(f\"{model_name}: {title}\", fontsize=16); plt.show()\n",
        "\n",
        "# --- Execution ---\n",
        "print(\"Finding errors...\")\n",
        "mb_fps, mb_fns = find_errors(best_mobilenet, val_loader)\n",
        "op_fps, op_fns = find_errors(best_opnet, val_loader)\n",
        "\n",
        "# Grad-CAM Hooks\n",
        "cam_mb = GradCAM(best_mobilenet, best_mobilenet.features[-1])\n",
        "cam_op = GradCAM(best_opnet, best_opnet.block4[0]) # OPNet Target Layer\n",
        "\n",
        "# Visualize\n",
        "print(\"Visualizing MobileNetV2 Errors...\")\n",
        "plot_analysis(mb_fps, cam_mb, \"MobileNetV2\", \"False Positives\")\n",
        "plot_analysis(mb_fns, cam_mb, \"MobileNetV2\", \"False Negatives\")\n",
        "\n",
        "print(\"\\nVisualizing OPNet Errors...\")\n",
        "plot_analysis(op_fps, cam_op, \"OPNet\", \"False Positives\")\n",
        "plot_analysis(op_fns, cam_op, \"OPNet\", \"False Negatives\")\n",
        "\n",
        "cam_mb.remove(); cam_op.remove()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMnIYfhb9/2eM2t8lb2pjmx",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "1ms2QdHy4WNpl_fkY7_QvLCuX6YaZxeMa",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
