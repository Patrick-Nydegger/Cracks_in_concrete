# ðŸ”¬ Experiment Journal: 
# Use case: Automatic inspection of bridge piers and detection of cracks in concrete

---

## **Project Details**

> **Institution:** ðŸ›ï¸ FHNW School of Business
>
> **Module:** ðŸ“š Deep Learning (HS 2025)
>
> **Authors:** ðŸ‘¥ Oliver Gwerder, Patrick Nydegger
>
> **Date:** ðŸ“… October - December 2025
>
> **Weight:** âš–ï¸ 30% of the final module grade

---
## Main Objective

> To develop and evaluate a Convolutional Neural Network (CNN) capable of accurately classifying images of concrete surfaces as either "Cracked" or "Non-cracked".

```
ðŸŽ¯ Zielsetzung und Prozess
Eine Drohne fliegt einen vordefinierten Kurs entlang eines Objekts (z. B. BrÃ¼ckenpfeiler). Sie nimmt dabei kontinuierlich Bilder auf. Das Deep-Learning-Modell verarbeitet diese Bilder automatisch in Echtzeit oder nach dem Flug und digitalisiert die erkannten Risse (Markierung, Speicherung der GPS-Position und der Bilddatei). Das Ziel ist eine vollstÃ¤ndige, lÃ¼ckenlose Erfassung aller SchÃ¤den.

â—ï¸ Konsequenz von Fehlern (Risikobewertung)
Falsch-Negativ (FN - Echter Riss wird Ã¼bersehen): Kritischer Fehler. Dies bedeutet, dass ein potenziell strukturell gefÃ¤hrlicher Riss nicht dokumentiert wird und unbehandelt bleibt. Die Konsequenz ist ein hohes Sicherheitsrisiko.

Falsch-Positiv (FP - Kein Riss wird als Riss markiert): Unkritischer Fehler. Dies fÃ¼hrt lediglich zu einer unnÃ¶tigen manuellen Nachkontrolle an dieser Stelle. Die Konsequenz sind hÃ¶here Betriebskosten, aber kein Sicherheitsrisiko.

ðŸ“Š Empfohlene Metrik
PrimÃ¤re Metrik: Sensitivity (Recall/Trefferquote)

BegrÃ¼ndung: Wir mÃ¼ssen die Anzahl der Falsch-Negativen (FN) minimieren. Die SensitivitÃ¤t beantwortet die Frage: "Von allen tatsÃ¤chlichen Rissen, wie viele hat das Modell gefunden?" Hier ist es akzeptabel, einen niedrigeren Schwellenwert zu wÃ¤hlen, um die Wahrscheinlichkeit zu maximieren, jeden Riss zu finden.

SekundÃ¤re Metrik: Precision (PrÃ¤zision), um zu gewÃ¤hrleisten, dass der Workflow durch zu viele unnÃ¶tige Kontrollpunkte nicht Ã¼berlastet wird.

ðŸ§‘â€ðŸ’» Anwendungsfall 2: Manuelle Bildkontrolle / QualitÃ¤tssicherung
ðŸŽ¯ Zielsetzung und Prozess
Ingenieure oder Techniker erstellen manuell eine Auswahl von Bildern von verdÃ¤chtigen Stellen. Das Modell wird als UnterstÃ¼tzung oder zweite Meinung eingesetzt, um schnell zu entscheiden, ob ein Bild zur weiteren Detailanalyse an einen SachverstÃ¤ndigen weitergeleitet werden muss ("Hat dieses Bild einen Riss: Ja/Nein?"). Die ZuverlÃ¤ssigkeit der Klassifikation steht im Vordergrund.

â—ï¸ Konsequenz von Fehlern (Risikobewertung)
Falsch-Negativ (FN - Echter Riss wird Ã¼bersehen): Mittlerer Fehler. Da die manuelle Auswahl bereits eine VerdachtsflÃ¤che war, ist das Risiko geringer als bei der Drohne, aber immer noch unerwÃ¼nscht.

Falsch-Positiv (FP - Kein Riss wird als Riss markiert): Kritischer Fehler. Da jedes als positiv markierte Bild zu einer teuren, zeitaufwÃ¤ndigen Detailanalyse durch einen hoch bezahlten Experten fÃ¼hrt, mÃ¼ssen Falsch-Positive minimiert werden.

ðŸ“Š Empfohlene Metrik
PrimÃ¤re Metrik: Precision (PrÃ¤zision)

BegrÃ¼ndung: Wir mÃ¼ssen die Anzahl der Falsch-Positiven (FP) minimieren. Die PrÃ¤zision beantwortet die Frage: "Von allen Bildern, die das Modell als Riss erkannt hat, wie viele waren tatsÃ¤chlich Risse?" Hier wÃ¤hlen wir einen hÃ¶heren Schwellenwert, um sicherzustellen, dass jede Meldung des Modells sehr zuverlÃ¤ssig ist.

SekundÃ¤re Metrik: Sensitivity (Recall), um zu verhindern, dass das Modell zwar prÃ¤zise, aber nutzlos wird, weil es fast gar keine Risse meldet.
```
## Project Summary

> This project involves the entire machine learning workflow, from data analysis and preprocessing to the implementation of a baseline model and a custom-designed CNN. We will document our experiments, compare model performance using appropriate metrics, and analyze the results to determine the most effective approach for automated crack detection.

---

## ðŸ“‹ Project Checklist & Table of Contents

- [ ] 1. Dataset Description and Analysis
- [ ] 2. Data Splitting Strategy
- [ ] 3. Choice of Evaluation Metrics
- [ ] 4. Data Augmentation Strategy
- [ ] 5. Choice of Loss Function
- [ ] 6. Baseline Model Selection
- [ ] 7. Custom Model Design
- [ ] 8. Performance Analysis
- [ ] 9. Parameter Studies & Experiments
- [ ] 10. Error Analysis (Failure Cases)
- [ ] 11. (Bonus) Explainability Analysis

---

### 1. Dataset Description and Analysis
*   **Dataset Source:**
*   **Content:**
*   **Image Properties:**
    *   Dimensions:
    *   Color Space:
    *   Total number of images:
*   **Class Distribution Analysis:**
    *   **Class "Cracked":**
    *   **Class "Non-Cracked":**
    *   **Imbalance:**
    *   **Visualization:**

### 2. Data Splitting Strategy
*   **Existing Split:**
*   **Splitting Method:**
    *   **Ratio:**
    *   **Stratification:**
*   **Final Split Counts:**
    *   **Training Set:**
    *   **Validation Set:**
    *   **Test Set:**

### 3. Choice of Evaluation Metrics
*   **Primary Metric:**
*   **Justification:**
*   **Secondary Metrics:**
    *   Accuracy:
    *   Sensitivity (Recall):
    *   Specificity:
    *   Precision:

### 4. Data Augmentation Strategy
*   **Necessity:**
*   **Selected Techniques & Justification:**
*   
  - [ ] Horizontal/Vertical Flips
  - [ ] Rotations
  - [ ] Brightness/Contrast Adjustments
  - [ ] Zoom
    *   `[ ]` Rotations
    *   `[ ]` Brightness/Contrast Adjustments
    *   `[ ]` Zoom
 
*   

### 5. Choice of Loss Function
*   **Selected Loss Function:**
*   **Justification:**

### 6. Baseline Model Selection
*   **Chosen Architecture:**
*   **Reason for Choice:**

### 7. Custom Model Design
*   **Architecture Overview:**
    *   Number of convolutional layers:
    *   Activation functions used:
    *   Pooling layers:
    *   Regularization:
    *   Classifier head:
*   **Design Justification:**

### 8. Performance Analysis
*   **Comparison Table:**

    | ID  | Model         | Accuracy | F1-Score | Recall | Precision |
    |-----|---------------|----------|----------|--------|-----------|
    | 001 | **Baseline**  |          |          |        |           |
    | 002 | **Custom CNN**|          |          |        |           |
    | 003 |               |          |          |        |           |

* **Training Curves:**
*   **Interpretation:**

### 9. Parameter Studies & Experiments
*   **Objective:**
*   **Experiment 1: Learning Rate Tuning**
*   **Experiment 2: Batch Size**
*   **Experiment 3: Data Augmentation Intensity**

### 10. Error Analysis (Failure Cases)
*   **Analysis of Misclassifications:**
    *   **False Positives (Non-Cracked predicted as Cracked):**
    *   **False Negatives (Cracked predicted as Non-Cracked):**
*   **Hypothesis:**

### 11. (Bonus) Explainability Analysis
*   **Method Used:**
*   **Findings:**
*   **Insights:**
